{
 "cells": [
  {
   "cell_type": "raw",
   "id": "7ec40059",
   "metadata": {},
   "source": [
    "!pip -q install langchain openai tiktoken"
   ]
  },
  {
   "cell_type": "raw",
   "id": "78d31e26",
   "metadata": {},
   "source": [
    "!pip install wikipedia"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca841467",
   "metadata": {},
   "source": [
    "!pip install PyPDF2\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "63926463",
   "metadata": {},
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d60dd5f0",
   "metadata": {},
   "source": [
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad6ec3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d82533c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import (\n",
    "    LlamaCppEmbeddings, \n",
    "    HuggingFaceEmbeddings, \n",
    "    SentenceTransformerEmbeddings\n",
    ")\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.document_loaders import (\n",
    "    PyPDFLoader,\n",
    "    DataFrameLoader,\n",
    "    GitLoader\n",
    "  )\n",
    "import pandas as pd\n",
    "import nbformat\n",
    "from nbconvert import PythonExporter\n",
    "import os\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5950211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = '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'\n",
    "#os.environ[\"OPENAI_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "d1863748",
   "metadata": {},
   "source": [
    "# location of the pdf file/files. \n",
    "doc_reader = PdfReader('Ramayana.pdf')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5210757b",
   "metadata": {},
   "source": [
    "# read data from the file and put them into a variable called raw_text\n",
    "raw_text = ''\n",
    "for i, page in enumerate(doc_reader.pages):\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        raw_text += text"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fdb0679b",
   "metadata": {},
   "source": [
    "len(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98394eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting up the text into smaller chunks for indexing\n",
    "text_splitter = CharacterTextSplitter(        \n",
    "    separator = \"\\n\",\n",
    "    chunk_size = 1000,\n",
    "    chunk_overlap  = 200, #striding over the text\n",
    "    length_function = len,\n",
    ")\n",
    "texts = text_splitter.split_text(raw_text)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "512bc3d0",
   "metadata": {},
   "source": [
    "texts[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83325aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = PyPDFLoader(\"mahabharata.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540de19f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e9587e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc5d1f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_splits(pdf_file):\n",
    "  \"\"\"Function takes in the pdf data and returns the  \n",
    "  splits so for further processing can be done.\"\"\"\n",
    "  \n",
    "  loader = PyPDFLoader(pdf_file)\n",
    "  pages = loader.load_and_split()  \n",
    "\n",
    "  textSplit = RecursiveCharacterTextSplitter(chunk_size=150,\n",
    "                                             chunk_overlap=15,\n",
    "                                             length_function=len)\n",
    "  doc_list = []\n",
    "  #Pages will be list of pages, so need to modify the loop\n",
    "  for pg in pages:\n",
    "    pg_splits = textSplit.split_text(pg.page_content.replace('\\n', ''))\n",
    "    doc_list.extend(pg_splits)\n",
    "\n",
    "  return doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba79ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_index(doc_list, embed_fn, index_store):\n",
    "  \"\"\"Function takes in existing vector_store, \n",
    "  new doc_list and embedding function that is \n",
    "  initialized on appropriate model. Local or online. \n",
    "  New embedding is merged with the existing index. If no \n",
    "  index given a new one is created\"\"\"\n",
    "  #check whether the doc_list is documents, or text\n",
    "  try:\n",
    "    faiss_db = FAISS.from_documents(doc_list, \n",
    "                              embed_fn)  \n",
    "  except Exception as e:\n",
    "    faiss_db = FAISS.from_texts(doc_list, \n",
    "                              embed_fn)\n",
    "  \n",
    "  if os.path.exists(index_store):\n",
    "    local_db = FAISS.load_local(index_store,embed_fn)\n",
    "    #merging the new embedding with the existing index store\n",
    "    local_db.merge_from(faiss_db)\n",
    "    print(\"Merge completed\")\n",
    "    local_db.save_local(index_store)\n",
    "    print(\"Updated index saved\")\n",
    "  else:\n",
    "    faiss_db.save_local(folder_path=index_store)\n",
    "    print(\"New store created...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e15db93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_docs_length(index_path, embed_fn):\n",
    "  test_index = FAISS.load_local(index_path,\n",
    "                              embeddings=embed_fn)\n",
    "  test_dict = test_index.docstore._dict\n",
    "  return len(test_dict.values())  \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c2de354",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "182c878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New store created...\n"
     ]
    }
   ],
   "source": [
    "pdf_docs = get_pdf_splits(\"mahabharata.pdf\")\n",
    "\n",
    "embed_index(doc_list=pdf_docs,\n",
    "            embed_fn=embeddings,\n",
    "            index_store='pdf_book2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17ee2363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5513"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_docs_length(index_path='pdf_book2',embed_fn=embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a650368f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = FAISS.load_local(\"pdf_book2\",embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0af49173",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"how did abhimanyu die?\"\n",
    "docs = docsearch.similarity_search(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6723d3c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"main cause of Abhimanyu's death. He it was who had effectively prevented t he relief of Abhimanyu by the Pandavas, and thereby caused Abhimanyu to be\", metadata={}),\n",
       " Document(page_content=\"him, but they fell like moths in the fire, one after another. Abhimanyu's shafts sea rched the weak points in the armor of his enemies. And the bodies\", metadata={}),\n",
       " Document(page_content='THE DEATH OF ABH IMANYU  THE Pandavas, proceeding according to plan, had closely followed Abhimanyu when he b roke into the Kaurava formation. But', metadata={}),\n",
       " Document(page_content='Abhimanyu to be isolated, overpowered and slain.  We have seen how Yudhishthira in his anxiety sent first Satyaki and then Bhima to join Arjuna in his', metadata={})]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328336b4",
   "metadata": {},
   "source": [
    "## Local LLM QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a816277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in mixed int8. Either pass torch_dtype=torch.float16 or don't pass this argument at all to remove this warning.\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import HuggingFacePipeline\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_id = 'google/flan-t5-small'# go for a smaller model if you dont have the VRAM\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id, load_in_8bit=True, device_map=\"auto\")\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=200\n",
    ")\n",
    "\n",
    "local_llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6f7e4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"Answer based on context:\\n\\n{context}\\n\\n{question}\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc206e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec954dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.question_answering import load_qa_chain\n",
    "chain = load_qa_chain(llm=local_llm, prompt=PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4ebbffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain({\"input_documents\": docs, \"question\": query}, return_only_outputs=True)[\n",
    "    \"output_text\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37236109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'roke into the Kaurava formation'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4888689c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b7d115",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837bd432",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
